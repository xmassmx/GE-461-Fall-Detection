# -*- coding: utf-8 -*-
"""GE4.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1X6eeZAAA-XF6L7UinZHr4kCFWefNnO5m
"""

# Sklearn functions used and References
# [1] https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html
# [2] https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html
# [3] https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html
# [4] https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html
# [5] https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html#sklearn.neural_network.MLPClassifier

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.decomposition import PCA
from sklearn.preprocessing import StandardScaler
import matplotlib.pyplot as plt
from sklearn.svm import SVC
from sklearn.cluster import KMeans
from sklearn.neural_network import MLPClassifier 



data = pd.read_csv('falldetection_dataset.csv', header = None)# read data
data = data.drop(0, axis = 1)# 0 column is index so drop it
data = data.replace('F', 1)# dummy encode labels
data = data.replace('NF', 0)# dummy encode labels
labels = data[1]# extract labels
cl = ['NF','F']
data = data.drop(1, axis = 1)#drop labels column from df
data.head()

scaler = StandardScaler()# [1]
data_norm = scaler.fit(data).transform(data)# standardize data (center and normalize)


""" PART A """
pca = PCA()# [2]
pca.fit(data_norm)# fit data on PCA


plt.plot(np.cumsum(pca.explained_variance_ratio_))# plot of cummulative sum of explained variance ratio
plt.xlabel('Principal Component')
plt.ylabel('Explained variance ratio')
plt.title('PCA explained variance ratio vs. PCs')
plt.grid()
plt.show()
print(pca.explained_variance_ratio_[0],pca.explained_variance_ratio_[1])#top two PCs explained variance ratio

pca2 = PCA(2)# [2]
data_pca = pca2.fit_transform(data_norm)# fit data to PCA with 2 dimesnions

for i in range(2):
  ind = np.where(labels == i)[0]#find index of each label
  plt.plot(data_pca[ind,0],data_pca[ind,1], 'o',label = cl[i],markersize=3)#plot the data as scatter plot

plt.title('Scatter plot of data projected to two dimensions using PCA.')
plt.legend()
plt.show()

"""#Kmeans"""


N = 2
kmeans = KMeans(n_clusters=N).fit(data_pca)# [3] fit data to kmeans with two clusters
for i in range(N):
  ind = np.where(kmeans.labels_ == i)[0]# plot the result of the kmeans
  
  plt.plot(data_pca[ind,0],data_pca[ind,1], 'o',label = i, markersize = 3)
  plt.plot(kmeans.cluster_centers_[i,0],kmeans.cluster_centers_[i,1],'o', markersize = 5)# plot cluster centers


plt.title('Scatter plot of output of Kmeans with N=2')
plt.legend()
plt.show()
sum(kmeans.labels_ == labels.to_numpy())/len(labels)# %of points with the same label with the kmeans

j = []
for N1 in range(1,21):
  kmeans1 = KMeans(n_clusters=N1).fit(data_pca)# [3]  iterate wrt the number of clusters to get elbow plot of inertia
  j.append(kmeans1.inertia_)

plt.plot(np.arange(1,21),j)
plt.title('Inertia vs. Number of clusters.')
plt.xlabel('number of clusters')
plt.ylabel('Inertia')
plt.show()

""" PART B """


"""#PCA Data

##SVM
"""

data_train, data_test, labels_train, labels_test = train_test_split(data_pca, labels, test_size=0.15)# split data
data_train, data_val, labels_train, labels_val = train_test_split(data_train, labels_train, test_size=0.176)# split data

kernels = ['rbf','linear', 'poly',  'sigmoid']# kernels available
score_list = []
for k in kernels:# fit SVMover all kernels
  svm = SVC(kernel = k)# [4] 
  svm.fit(data_train, labels_train)
  score_list.append(svm.score(data_val, labels_val)*100)
plt.plot(kernels, score_list, 'x--')#plot accuracy vs kernel
plt.title('Validation accuracy vs. Kernels used')
plt.show()

dim = np.arange(2,21)
score_list1 = []
for k in dim:# iterate through degree parameter of polynomial kernel
  svm = SVC(kernel = "poly", degree = k, C=1)# [4] 
  svm.fit(data_train, labels_train)
  score_list1.append(svm.score(data_val, labels_val)*100)
plt.plot(dim, score_list1, 'x--')
plt.title('Validation accuracy vs. polynomial degree')
plt.xlabel('Polynomial degree')
plt.ylabel('Accuracy')
plt.show()

dim = np.arange(1,1000)
score_list1 = []
for k in dim:# iterate through values of regularization parameter
  svm = SVC(kernel = "rbf",  C=k)# [4] 
  svm.fit(data_train, labels_train)
  score_list1.append(svm.score(data_val, labels_val)*100)
plt.plot(dim, score_list1, 'x--')
plt.title('Validation accuracy vs. polynomial degree')
plt.xlabel('Regularization parameter value')
plt.ylabel('Accuracy')
plt.show()

svm = SVC(kernel = "rbf",  C=350)# [4] 
svm.fit(data_train, labels_train)#fit the best model
score_list1.append(svm.score(data_val, labels_val)*100)# validation accuracy on best model
score_list1[-1]

# Best model is the rbf model
svm = SVC(kernel = "rbf",  C=350)
svm.fit(data_train, labels_train)
score_lin = svm.score(data_test, labels_test)# test accuracy of best model
score_lin = score_lin*100
print(score_lin)



"""##MLP"""



layers = [(4,2),(4,4),(2,2),(8,4)]# layer configurations to run
mlp_pca = []
mlp_loss = []

for l in layers:
  clf = MLPClassifier(hidden_layer_sizes=l, activation = 'relu', max_iter = 5000,
                      solver='adam',learning_rate_init = 0.005,alpha = 0.0001,
                      shuffle = True, momentum = 0.9, learning_rate = 'adaptive').fit(data_train, labels_train)# [5] train model
  print(clf.score(data_val, labels_val))
  mlp_pca.append(clf.score(data_val, labels_val))# validation accuracy
  mlp_loss.append(clf.loss_curve_)# loss curve
  plt.plot(clf.loss_curve_, label = str(l))# plot loss curve
plt.title('Loss curve')
plt.ylabel('loss')
plt.legend()
plt.show()

print(clf.score(data_test, labels_test))# test accuracy

"""#Original Data"""

# Same as for the PCA data but with original data and hyperparameters tuned accordingly

data_train, data_test, labels_train, labels_test = train_test_split(data_norm, labels, test_size=0.15)# split data
data_train, data_val, labels_train, labels_val = train_test_split(data_train, labels_train, test_size=0.176)# split data

"""##SVM"""

kernels = ['rbf','linear', 'poly',  'sigmoid']
score_list = []
for k in kernels:
  svm = SVC(kernel = k)# [4] 
  svm.fit(data_train, labels_train)
  score_list.append(svm.score(data_val, labels_val)*100)
plt.plot(kernels, score_list, 'x--')
plt.title('Validation accuracy vs. Kernels used')
plt.show()

dim = np.arange(2,16)
score_list1 = []
for k in dim:
  svm = SVC(kernel = "poly", degree = k, C=1)# [4] 
  svm.fit(data_train, labels_train)
  score_list1.append(svm.score(data_val, labels_val)*100)
plt.plot(dim, score_list1, 'x--')
plt.title('Validation accuracy vs. polynomial degree')
plt.show()

# Best model is the linear model or the poly w/ deg 3
svm = SVC(kernel = "linear")# [4] 
svm.fit(data_train, labels_train)
score_lin = svm.score(data_test, labels_test)
score_lin = score_lin*100
print(score_lin)


svm = SVC(kernel = "poly", degree = 3)# [4] 
svm.fit(data_train, labels_train)
score_poly = svm.score(data_test, labels_test)
score_poly = score_poly * 100
print(score_poly)

"""##MLP"""



clf = MLPClassifier(hidden_layer_sizes=(16,8,), activation = 'relu', max_iter = 1000,
                    solver='adam',learning_rate_init = 0.04,alpha = 0.02,
                    shuffle = True, momentum = 0.9, learning_rate = 'adaptive', tol = 1e-6).fit(data_train, labels_train)# [5] 
clf.score(data_val, labels_val)

clf.score(data_test, labels_test)

plt.plot(clf.loss_curve_)
plt.title('Loss curve')
plt.ylabel('loss')
plt.show()

